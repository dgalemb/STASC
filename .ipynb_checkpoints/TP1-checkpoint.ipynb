{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nom : Daniel MACEDO GALEMBECK\n",
    "\n",
    "InfoIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation de méthodes élémentaires pour la classification supervisée : ADL, ADQ, Naive Bayes et classifieur par plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce TP, nous aurons besoin des modules Python ci-dessous, il vous faut donc évidemment exécuter cette première cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu de données [Vertebral Column](https://archive.ics.uci.edu/ml/datasets/Vertebral+Column) permet d'étudier les pathologies d'hernie discale et de Spondylolisthesis. Ces deux pathologies sont regroupées dans le jeu de données en une seule catégorie dite `Abnormale`. \n",
    "\n",
    "Il s'agit donc d'un problème de classification supervisée à deux classes :\n",
    "- Normale (NO) \n",
    "- Abnormale (AB)    \n",
    "\n",
    "avec 6 variables bio-mécaniques disponibles (features).\n",
    "\n",
    "L'objectif du TP est d'implémenter quelques méthodes simples de classification supervisée pour ce problème."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Télécharger le fichier column_2C.dat depuis le site de l'UCI à [cette adresse](https://archive.ics.uci.edu/ml/datasets/Vertebral+Column). \n",
    ">\n",
    "> On peut importer les données sous python par exemple avec la librairie [pandas](https://pandas.pydata.org/pandas-docs/stable/10min.html). Vous pourrez au besoin consulter la documentation de la fonction [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html). \n",
    "> \n",
    "> Le chemin donné dans la fonction `read_csv`est une chaîne de caractère qui spécifie le chemin complet vers le ficher sur votre machine. On peut aussi donner une adresse url si le fichier est disponible en ligne.\n",
    ">\n",
    "> Attention à la syntaxe pour les chemins sous Windows doit etre de la forme  `C:/truc/machin.csv`. \n",
    "> \n",
    "> Voir ce [blog](https://medium.com/@ageitgey/python-3-quick-tip-the-easy-way-to-deal-with-file-paths-on-windows-mac-and-linux-11a072b58d5f) pour en savoir plus sur la \"manipulation des chemins\" sur des OS variés. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mData\u001b[m\u001b[m                       Scientific Computing.ipynb\r\n",
      "Intro_Python.ipynb         Statistics.ipynb\r\n",
      "Plotting.ipynb             TP1.ipynb\r\n",
      "README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>42.69</td>\n",
       "      <td>30.26</td>\n",
       "      <td>125.00</td>\n",
       "      <td>13.29</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36.69</td>\n",
       "      <td>5.01</td>\n",
       "      <td>41.95</td>\n",
       "      <td>31.68</td>\n",
       "      <td>84.24</td>\n",
       "      <td>0.66</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49.71</td>\n",
       "      <td>13.04</td>\n",
       "      <td>31.33</td>\n",
       "      <td>36.67</td>\n",
       "      <td>108.65</td>\n",
       "      <td>-7.83</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.23</td>\n",
       "      <td>17.72</td>\n",
       "      <td>15.50</td>\n",
       "      <td>13.52</td>\n",
       "      <td>120.06</td>\n",
       "      <td>0.50</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.92</td>\n",
       "      <td>19.96</td>\n",
       "      <td>40.26</td>\n",
       "      <td>28.95</td>\n",
       "      <td>119.32</td>\n",
       "      <td>8.03</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.57</td>\n",
       "      <td>20.46</td>\n",
       "      <td>33.10</td>\n",
       "      <td>33.11</td>\n",
       "      <td>110.97</td>\n",
       "      <td>7.04</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.30</td>\n",
       "      <td>24.19</td>\n",
       "      <td>47.00</td>\n",
       "      <td>33.11</td>\n",
       "      <td>116.81</td>\n",
       "      <td>5.77</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44.32</td>\n",
       "      <td>12.54</td>\n",
       "      <td>36.10</td>\n",
       "      <td>31.78</td>\n",
       "      <td>124.12</td>\n",
       "      <td>5.42</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>63.83</td>\n",
       "      <td>20.36</td>\n",
       "      <td>54.55</td>\n",
       "      <td>43.47</td>\n",
       "      <td>112.31</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.28</td>\n",
       "      <td>3.14</td>\n",
       "      <td>32.56</td>\n",
       "      <td>28.13</td>\n",
       "      <td>129.01</td>\n",
       "      <td>3.62</td>\n",
       "      <td>AB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
       "0             43.79        13.53                  42.69         30.26   \n",
       "1             36.69         5.01                  41.95         31.68   \n",
       "2             49.71        13.04                  31.33         36.67   \n",
       "3             31.23        17.72                  15.50         13.52   \n",
       "4             48.92        19.96                  40.26         28.95   \n",
       "5             53.57        20.46                  33.10         33.11   \n",
       "6             57.30        24.19                  47.00         33.11   \n",
       "7             44.32        12.54                  36.10         31.78   \n",
       "8             63.83        20.36                  54.55         43.47   \n",
       "9             31.28         3.14                  32.56         28.13   \n",
       "\n",
       "   pelvic_radius  degree_spondylolisthesis class  \n",
       "0         125.00                     13.29    AB  \n",
       "1          84.24                      0.66    AB  \n",
       "2         108.65                     -7.83    AB  \n",
       "3         120.06                      0.50    AB  \n",
       "4         119.32                      8.03    AB  \n",
       "5         110.97                      7.04    AB  \n",
       "6         116.81                      5.77    AB  \n",
       "7         124.12                      5.42    AB  \n",
       "8         112.31                     -0.62    AB  \n",
       "9         129.01                      3.62    AB  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path= \"Data/column_2C.dat\"\n",
    "Vertebral = pd.read_csv(file_path,\n",
    "                          delim_whitespace= \" \",\n",
    "                          header = 7)\n",
    "Vertebral.columns = [\"pelvic_incidence\",\n",
    "                                       \"pelvic_tilt\",\n",
    "                                       \"lumbar_lordosis_angle\",\n",
    "                                       \"sacral_slope\",\n",
    "                                       \"pelvic_radius\",\n",
    "                                       \"degree_spondylolisthesis\",\n",
    "                                       \"class\"]\n",
    "\n",
    "Vertebral.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Vérifier à l'aide des méthodes `.head()`  et `describe()` que les données sont bien importées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pelvic_incidence</th>\n",
       "      <th>pelvic_tilt</th>\n",
       "      <th>lumbar_lordosis_angle</th>\n",
       "      <th>sacral_slope</th>\n",
       "      <th>pelvic_radius</th>\n",
       "      <th>degree_spondylolisthesis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>302.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.678576</td>\n",
       "      <td>17.578245</td>\n",
       "      <td>52.383576</td>\n",
       "      <td>43.100662</td>\n",
       "      <td>118.073146</td>\n",
       "      <td>26.935563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.327303</td>\n",
       "      <td>10.094608</td>\n",
       "      <td>18.530151</td>\n",
       "      <td>13.525625</td>\n",
       "      <td>13.364007</td>\n",
       "      <td>37.830830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>26.150000</td>\n",
       "      <td>-6.550000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>70.080000</td>\n",
       "      <td>-11.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.490000</td>\n",
       "      <td>10.667500</td>\n",
       "      <td>37.207500</td>\n",
       "      <td>33.347500</td>\n",
       "      <td>110.887500</td>\n",
       "      <td>1.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.805000</td>\n",
       "      <td>16.420000</td>\n",
       "      <td>50.635000</td>\n",
       "      <td>42.460000</td>\n",
       "      <td>118.405000</td>\n",
       "      <td>13.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.917500</td>\n",
       "      <td>21.937500</td>\n",
       "      <td>63.092500</td>\n",
       "      <td>52.880000</td>\n",
       "      <td>125.562500</td>\n",
       "      <td>42.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>129.830000</td>\n",
       "      <td>49.430000</td>\n",
       "      <td>125.740000</td>\n",
       "      <td>121.430000</td>\n",
       "      <td>163.070000</td>\n",
       "      <td>418.540000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pelvic_incidence  pelvic_tilt  lumbar_lordosis_angle  sacral_slope  \\\n",
       "count        302.000000   302.000000             302.000000    302.000000   \n",
       "mean          60.678576    17.578245              52.383576     43.100662   \n",
       "std           17.327303    10.094608              18.530151     13.525625   \n",
       "min           26.150000    -6.550000              14.000000     13.370000   \n",
       "25%           46.490000    10.667500              37.207500     33.347500   \n",
       "50%           58.805000    16.420000              50.635000     42.460000   \n",
       "75%           73.917500    21.937500              63.092500     52.880000   \n",
       "max          129.830000    49.430000             125.740000    121.430000   \n",
       "\n",
       "       pelvic_radius  degree_spondylolisthesis  \n",
       "count     302.000000                302.000000  \n",
       "mean      118.073146                 26.935563  \n",
       "std        13.364007                 37.830830  \n",
       "min        70.080000                -11.060000  \n",
       "25%       110.887500                  1.637500  \n",
       "50%       118.405000                 13.485000  \n",
       "75%       125.562500                 42.027500  \n",
       "max       163.070000                418.540000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vertebral.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Les librairies de Machine Learning telles que `sckitlearn` prennent en entrée des tableau numpy (pas des objets pandas). Créer un tableau numpy que vous nommerez `VertebralVar` pour les features et un vecteur numpy `VertebralClas` pour la variable de classe. Voir par exemple [ici](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_numpy.html#pandas.DataFrame.to_numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 43.79,  13.53,  42.69,  30.26, 125.  ,  13.29],\n",
       "        [ 36.69,   5.01,  41.95,  31.68,  84.24,   0.66],\n",
       "        [ 49.71,  13.04,  31.33,  36.67, 108.65,  -7.83],\n",
       "        ...,\n",
       "        [ 61.45,  22.69,  46.17,  38.75, 125.67,  -2.71],\n",
       "        [ 45.25,   8.69,  41.58,  36.56, 118.55,   0.21],\n",
       "        [ 33.84,   5.07,  36.64,  28.77, 123.95,  -0.2 ]]),\n",
       " array(['AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO', 'NO',\n",
       "        'NO', 'NO', 'NO', 'NO', 'NO'], dtype=object))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VertebralVar  = np.array(Vertebral.iloc[:,[0,1,2,3,4,5]])\n",
    "VertebralClas = np.array(Vertebral.iloc[:,6])\n",
    "VertebralVar, VertebralClas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Découpage train / test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En apprentissage statistique, classiquement un prédicteur est ajusté sur une partie seulement des données et l'erreur de ce dernier est ensuite évaluée sur une autre partie des données disponibles. Ceci permet de ne pas utiliser les mêmes données pour ajuster et évaluer la qualité d'un prédicteur. Cette problématique est l'objet du prochain chapitre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> En utilisant la fonction [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) de la librairie [`sklearn.model_selection`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection), sélectionner aléatoirement 60% des observations pour l'échantillon d'apprentissage et garder le reste pour l'échantillon de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 181 121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 38.7 ,  13.44,  31.  ,  25.25, 123.16,   1.43],\n",
       "        [ 63.17,   6.33,  63.  ,  56.84, 110.64,  42.61],\n",
       "        [ 47.74,  12.09,  39.  ,  35.66, 117.51,  21.68],\n",
       "        ...,\n",
       "        [ 57.3 ,  24.19,  47.  ,  33.11, 116.81,   5.77],\n",
       "        [ 69.76,  19.28,  48.5 ,  50.48,  96.49,  51.17],\n",
       "        [ 54.12,  26.65,  35.33,  27.47, 121.45,   1.57]]),\n",
       " array(['AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'NO',\n",
       "        'AB', 'AB', 'NO', 'AB', 'AB', 'NO', 'AB', 'NO', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'NO', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO',\n",
       "        'AB', 'AB', 'AB', 'NO', 'AB', 'NO', 'AB', 'NO', 'NO', 'AB', 'AB',\n",
       "        'AB', 'NO', 'NO', 'NO', 'NO', 'AB', 'AB', 'AB', 'NO', 'NO', 'NO',\n",
       "        'AB', 'NO', 'NO', 'NO', 'NO', 'NO', 'AB', 'AB', 'NO', 'NO', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO', 'AB', 'AB', 'NO', 'AB',\n",
       "        'NO', 'AB', 'AB', 'AB', 'NO', 'AB', 'AB', 'NO', 'NO', 'AB', 'NO',\n",
       "        'AB', 'NO', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'NO', 'NO', 'AB',\n",
       "        'AB', 'NO', 'NO', 'AB', 'NO', 'AB', 'AB', 'AB', 'NO', 'AB', 'AB',\n",
       "        'AB', 'AB', 'NO', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'NO', 'AB',\n",
       "        'NO', 'AB', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB', 'NO', 'NO',\n",
       "        'AB', 'AB', 'NO', 'AB', 'AB', 'NO', 'AB', 'NO', 'AB', 'AB', 'AB',\n",
       "        'AB', 'NO', 'NO', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB', 'AB',\n",
       "        'AB', 'AB', 'AB', 'AB', 'NO', 'AB', 'AB', 'AB', 'AB', 'AB', 'NO',\n",
       "        'AB', 'AB', 'AB', 'AB', 'AB'], dtype=object))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "VertebralVar_train,VertebralVar_test,VertebralClas_train, VertebralClas_test = train_test_split(VertebralVar, VertebralClas, test_size=0.4)\n",
    "ntot = len(VertebralVar_train) + len(VertebralVar_test)\n",
    "ntrain = len(VertebralVar_train)\n",
    "ntest = len(VertebralVar_test)\n",
    "\n",
    "print(ntot, ntrain, ntest)\n",
    "\n",
    "VertebralVar_train, VertebralClas_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : on peut aussi le faire à la main avec la fonction [`sklearn.utils.shuffle`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction des deux classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Extraire les deux sous-échantillons de classes respectives \"Abnormale\" et \"Normale\" pour les données d'apprentissage et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VertebralVar_train_AB = np.array([VertebralVar_train[j] for j,k in enumerate(VertebralClas_train) if k == 'AB'])\n",
    "VertebralVar_train_NO = np.array([VertebralVar_train[j] for j,k in enumerate(VertebralClas_train) if k == 'NO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "n_AB = len(VertebralVar_train_AB)\n",
    "n_NO = len(VertebralVar_train_NO)\n",
    "print(n_AB)\n",
    "print(n_NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ajuster un classifieur naif bayesien sur les données d'apprentissage.\n",
    "\n",
    "Pour une observation $x \\in \\mathbb R^6$, la régle du MAP consiste à choisir la catégorie $\\hat y (x) = \\hat k $ qui maximise (en $k$) \n",
    "$$ score_k(x) = \\hat \\pi_k \\prod_{j=1} ^6  \\hat f_{k,j}(x_j)   $$\n",
    "où :\n",
    "- $k$ est le numéro de la classe ;\n",
    "- $\\hat \\pi_k$ est la proportion observée de la classe $k$, \n",
    "- $\\hat f_{k,j} $ est la densité gaussienne univariée de la classe $k$ pour la variable $j$. Les paramètres de cette loi valent (ajustés par maximum de vraisemblance) :\n",
    "    - $\\hat \\mu_{k,j}$ : la moyenne empirique de la variable $X^j$ restreinte à la classe k,\n",
    "    - $ \\hat \\sigma^2_{k,j}$ : la variance empirique de la variable $X^j$ restreinte à la classe k.\n",
    "    \n",
    "Noter que la fonction $x \\mapsto  \\prod_{j=1} ^6  f_{k,j}(x_j) $ peut aussi être vue comme une densité gaussienne multidimensionnelle de moyenne $(\\mu_{k,1}, \\dots, \\mu_{k,6})$ et de matrice de covariance diagonale $diag(\\hat \\sigma^2_{k,1},\\dots,\\hat  \\sigma^2_{k,6})$. Cette remarque évite de devoir calculer le produit de 6 densités univariées, à la place on calcule plus directement la valeur de la densité multidimensionnelle.\n",
    "\n",
    "Pour calculer la valeur de la densité d'une gaussienne multidimensionnelle en un point $x$ de $\\mathbb R ^d$ on peut utililser la fonction [`multivariate_normal`](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.multivariate_normal.html) de la librairie [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html). \n",
    "\n",
    "On pourra utiliser la fonction `var` de numpy pour calculer le vecteur des variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul des moyennes et des variances de chaque variable pour chacun des deux groupes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_AB = VertebralVar_train_AB.mean(axis = 0)\n",
    "mean_NO = VertebralVar_train_NO.mean(axis = 0)\n",
    "# variances estimées variable par variable pour AB (sur le train) :\n",
    "var_AB = np.var(VertebralVar_train_AB, axis = 0) \n",
    "# variances estimées variable par variable pour NO (sur le train) :\n",
    "var_NO = np.var(VertebralVar_train_NO, axis = 0) \n",
    "\n",
    "# on forme les matrices de covariance (matrices diagonales car indep) :\n",
    "Cov_NB_AB = np.diag(var_AB)\n",
    "Cov_NB_NO = np.diag(var_NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul du \"score\" sur chaque groupe pour chaque element des données test : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_NB_test = [[n_AB * multivariate_normal.pdf(x, mean=mean_AB, cov=Cov_NB_AB),\n",
    "                n_NO * multivariate_normal.pdf(x, mean=mean_NO, cov=Cov_NB_NO)] \n",
    "                for x in VertebralVar_test]\n",
    "pred_NB_test = ['AB' if k[0] > k[1] else 'NO' for k in score_NB_test] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice de confusion est une matrice qui synthétise les performances d'une régle de classification. Chaque ligne correspond à une classe réelle, chaque colonne correspond à une classe estimée. La cellule (ligne L, colonne C) contient le nombre d'éléments de la classe réelle L qui ont été estimés comme appartenant à la classe C. Voir par exemple [ici](https://fr.wikipedia.org/wiki/Matrice_de_confusion).\n",
    "\n",
    "> Evaluer les performances de la méthode sur l'échantillon test. Vous pourrez utiliser la fonction [`confusion_matrix`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix) de la librairie [`sklearn.metrics`](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78947368, 0.21052632],\n",
       "       [0.13333333, 0.86666667]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_NB_test = confusion_matrix(VertebralClas_test, pred_NB_test)\n",
    "cnf_matrix_NB_test.astype('float') / cnf_matrix_NB_test.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Il existe bien sûr une fonction scikit-learn  pour la méthode Naive Bayes : voir [ici](http://scikit-learn.org/stable/modules/naive_bayes.html). Vérifier que votre prédicteur donne la même réponse de cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78947368, 0.21052632],\n",
       "       [0.13333333, 0.86666667]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(VertebralVar_train, VertebralClas_train).predict(VertebralVar_test)\n",
    "M = confusion_matrix(VertebralClas_test, y_pred)\n",
    "M.astype('float') / M.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur par plus proches voisins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est préférable d'utiliser la structure de données de type [k-d tree](https://en.wikipedia.org/wiki/K-d_tree) pour effectuer des requêtes de plus proches voisins dans un nuage de points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Contruction du k-d tree pour les données train (pour la métrique euclidienne) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "import pickle\n",
    "tree =  KDTree(VertebralVar_train, leaf_size=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Rechercher les 10 plus proches voisins dans les données d'apprentissage du premier point des données de test et afficher les classes de ces observations voisines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 150 151  69  61  16  95  27  22  29]\n",
      "['AB' 'NO' 'AB' 'NO' 'AB' 'NO' 'NO' 'NO' 'AB' 'AB']\n"
     ]
    }
   ],
   "source": [
    "dist, indices_voisins = tree.query(VertebralVar_train, k=10)\n",
    "indices_voisins = indices_voisins[0]\n",
    "print(indices_voisins)\n",
    "classes_voisins = VertebralClas_train[indices_voisins]\n",
    "print(classes_voisins)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le classifieur par plus proches vosins, la prediction est la classe majoritaire des k plus proches voisins.\n",
    "\n",
    "> Donner la prédiction pour le premier point de test par vote majoritaire sur ses 10 plus proches voisins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NO']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = ['AB' if np.count_nonzero(classes_voisins == 'AB') > 5 else 'NO']\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Donner la prediction du classifieur ppv pour toutes les données de test. Evaluer la qualité du classifieur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.82894737, 0.17105263],\n",
       "       [0.        , 1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_class = 5\n",
    "dist, indices_voisins = KDTree(VertebralVar_test, leaf_size=2).query(VertebralVar_test, k=k_class)\n",
    "pred_kNN_test = ['AB' if np.count_nonzero(k == 'AB') > 3 else 'NO' for k in VertebralClas_test[indices_voisins]] \n",
    "cnf_matrix_kNN = confusion_matrix(VertebralClas_test, pred_kNN_test)\n",
    "cnf_matrix_kNN.astype('float') / cnf_matrix_kNN.sum(axis=1).reshape(-1,1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe bien sûr une fonction scikit-learn pour le classifieur plus proche voisin, voir [ici](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "87fc21197254558951455343ce704bc14f1a5282bb938462d86fd102e291cdae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
